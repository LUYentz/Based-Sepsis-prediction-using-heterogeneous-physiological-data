{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %load Main.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PreProcess as PrePro\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "from keras.optimizers import Adam, SGD,RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import sklearn\n",
    "import math\n",
    "import unet_model\n",
    "import Data_Load\n",
    "import unet_info\n",
    "import common\n",
    "import pandas as pd\n",
    "import logging\n",
    "import argparse\n",
    "import time\n",
    "import segnet\n",
    "import maskrcnn\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T sne\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_TSNE(features,label,z,data_type,path):\n",
    "    pca = PCA(n_components=2)# 总的类别\n",
    "    nsamples, nx, ny, nz= features.shape \n",
    "    x = features.reshape([nsamples,nx*ny*nz])\n",
    "    pca_result = pca.fit_transform(x)\n",
    "    print('Variance PCA: {}'.format(np.sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "    #Run T-SNE on the PCA features.\n",
    "    tsne = TSNE(n_components=2, verbose = 1)\n",
    "    tsne_results = tsne.fit_transform(pca_result[:50])\n",
    "    #-------------------------------可视化--------------------------------\n",
    "    y_test_cat = np_utils.to_categorical(label[:50], num_classes = 2)# 总的类别\n",
    "    color_map = np.argmax(y_test_cat, axis=1)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for cl in range(2):# 总的类别\n",
    "        indices = np.where(color_map==cl)\n",
    "        indices = indices[0]\n",
    "        plt.scatter(tsne_results[indices,0], tsne_results[indices, 1], label=cl)\n",
    "    plt.legend()\n",
    "    plt.title(str(z)+'_'+data_type+'_T-sne')\n",
    "    plt.show()\n",
    "    plt.savefig(path+\"/\"+str(z)+'_'+data_type+'_T-sne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU setting completed.\n",
      "Tensorflow version: 1.10.0\n",
      "Keras version 2.2.0\n",
      "Dim ordering: tf\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "unet_info.begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n",
      "radom\n",
      "(154800, 1, 4096, 1)\n",
      "(50400, 1, 4096, 1)\n",
      "SepsisA2B2_NorAllday\n",
      "Finish Load data\n"
     ]
    }
   ],
   "source": [
    "subseq =4096\n",
    "#dbName  = \"SepsisDataset\"\n",
    "dbName  = \"SepsisDataset_random\"\n",
    "print(\"Load data\")\n",
    "X_train, X_test, Y_train, Y_test, N_FEATURES, classes = Data_Load.load_data(dbName,subseq)\n",
    "#get dense prediction results with overlap(transformed win data label's ground truth)\n",
    "# y_test_resh = y_test.reshape(y_test.shape[0], y_test.shape[2], -1)\n",
    "# y_test_resh_argmax = np.argmax(y_test_resh, axis=2)\n",
    "# labels_test_unary = y_test_resh_argmax.reshape(y_test_resh_argmax.size)\n",
    "# file_labels_test_unary = 'labels_gd_'+args.dataset+'_'+str(subseq)+'0317.npy'\n",
    "# np.save(file_labels_test_unary,labels_test_unary)\n",
    "print(\"Finish Load data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10-flod cross validation###\n",
    "epochs = 45 #50\n",
    "batch_size = 64 #64 #128\n",
    "optim_type = 'adam'\n",
    "learning_rate = 0.02 # 0.05 # 0.01 #0.02\n",
    "sum_time = 0\n",
    "net = 'unet'\n",
    "block = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nowtime = time.strftime(\"%m%d_%H%M\",time.localtime())\n",
    "s_path = 'Result/'+str(subseq)\n",
    "print('Patient subsep Floder created') if os.path.isdir(s_path) else os.mkdir(s_path)\n",
    "rf_path = s_path + '/'+nowtime + '_'+ str(subseq)\n",
    "print('Patient Floder created') if os.path.isdir(rf_path) else os.mkdir(rf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0162192333235769, 0.993811761], [0.0242311698568682, 0.993313653740156], [0.0216753581516536, 0.993578849251572], [0.0610394489308891, 0.980411279263114], [0.019811101, 0.990566599], [0.019553627, 0.993653495]]\n",
      "[[2.3045928918747673, 0.6679142737010169], [2.847108883479285, 0.6585575648716517], [2.192989231215583, 0.6919554695250496], [1.8850630738621665, 0.6757591998387897], [2.696897084977891, 0.6662840053013392], [2.61109272321065, 0.6860669671921503]]\n"
     ]
    }
   ],
   "source": [
    "rf_path = 'Result/4096/0406_1603_4096'\n",
    "nowtime = '0406_1603'\n",
    "valcvscores =[[0.0162192333235769 , 0.993811761],[0.0242311698568682,0.993313653740156],\n",
    "              [0.0216753581516536,0.993578849251572], [0.0610394489308891,0.980411279263114],\n",
    "              [0.019811101,0.990566599],[0.019553627,0.993653495]]\n",
    "testcvscores =[[2.3045928918747673 , 0.6679142737010169 ],[2.847108883479285,0.6585575648716517],\n",
    "              [2.192989231215583,0.6919554695250496], [1.8850630738621665,0.6757591998387897],\n",
    "              [2.696897084977891,0.6662840053013392],[2.61109272321065,0.6860669671921503]]\n",
    "#valcvscores  = []\n",
    "#testcvscores = []\n",
    "print(valcvscores)\n",
    "print(testcvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold Floder created\n",
      "6 Running...\n",
      "Train on 139320 samples, validate on 15480 samples\n",
      "Epoch 1/45\n",
      "139320/139320 [==============================] - 655s 5ms/step - loss: 0.2867 - acc: 0.8618 - val_loss: 0.1604 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16038, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 2/45\n",
      "139320/139320 [==============================] - 625s 4ms/step - loss: 0.0782 - acc: 0.9687 - val_loss: 0.1157 - val_acc: 0.9648\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16038 to 0.11566, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 3/45\n",
      "139320/139320 [==============================] - 624s 4ms/step - loss: 0.0542 - acc: 0.9780 - val_loss: 0.0809 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11566 to 0.08095, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 4/45\n",
      "139320/139320 [==============================] - 623s 4ms/step - loss: 0.0440 - acc: 0.9826 - val_loss: 0.0460 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08095 to 0.04599, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 5/45\n",
      "139320/139320 [==============================] - 621s 4ms/step - loss: 0.0377 - acc: 0.9847 - val_loss: 0.0560 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04599\n",
      "Epoch 6/45\n",
      "139320/139320 [==============================] - 621s 4ms/step - loss: 0.0328 - acc: 0.9867 - val_loss: 0.0775 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04599\n",
      "Epoch 7/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0305 - acc: 0.9881 - val_loss: 0.0535 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04599\n",
      "Epoch 8/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0273 - acc: 0.9891 - val_loss: 0.0267 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04599 to 0.02667, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 9/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0247 - acc: 0.9902 - val_loss: 0.0248 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02667 to 0.02481, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 10/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0231 - acc: 0.9910 - val_loss: 0.0216 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02481 to 0.02163, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 11/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0228 - acc: 0.9906 - val_loss: 0.0257 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02163\n",
      "Epoch 12/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0198 - acc: 0.9920 - val_loss: 0.0251 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02163\n",
      "Epoch 13/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0198 - acc: 0.9920 - val_loss: 0.0198 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02163 to 0.01982, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 14/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0181 - acc: 0.9930 - val_loss: 0.0316 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01982\n",
      "Epoch 15/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0182 - acc: 0.9927 - val_loss: 0.0229 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01982\n",
      "Epoch 16/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0163 - acc: 0.9935 - val_loss: 0.0241 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01982\n",
      "Epoch 17/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0170 - acc: 0.9930 - val_loss: 0.0199 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01982\n",
      "Epoch 18/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0173 - acc: 0.9929 - val_loss: 0.0222 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01982\n",
      "Epoch 19/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0152 - acc: 0.9942 - val_loss: 0.0178 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01982 to 0.01785, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 20/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0145 - acc: 0.9942 - val_loss: 0.0354 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01785\n",
      "Epoch 21/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0171 - acc: 0.9929 - val_loss: 0.0428 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01785\n",
      "Epoch 22/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0160 - acc: 0.9918 - val_loss: 0.0222 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01785\n",
      "Epoch 23/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0151 - acc: 0.9943 - val_loss: 0.0211 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01785\n",
      "Epoch 24/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0133 - acc: 0.9947 - val_loss: 0.0184 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01785\n",
      "Epoch 25/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0133 - acc: 0.9951 - val_loss: 0.0239 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01785\n",
      "Epoch 26/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0131 - acc: 0.9950 - val_loss: 0.0181 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01785\n",
      "Epoch 27/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0120 - acc: 0.9952 - val_loss: 0.0495 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01785\n",
      "Epoch 28/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0126 - acc: 0.9952 - val_loss: 0.0197 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01785\n",
      "Epoch 29/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0116 - acc: 0.9956 - val_loss: 0.0172 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01785 to 0.01720, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 30/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0112 - acc: 0.9955 - val_loss: 0.0264 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01720\n",
      "Epoch 31/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0113 - acc: 0.9957 - val_loss: 0.0309 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01720\n",
      "Epoch 32/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0122 - acc: 0.9954 - val_loss: 0.0177 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01720\n",
      "Epoch 33/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.0238 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01720\n",
      "Epoch 34/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0117 - acc: 0.9953 - val_loss: 0.0330 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01720\n",
      "Epoch 35/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0111 - acc: 0.9957 - val_loss: 0.0255 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01720\n",
      "Epoch 36/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0116 - acc: 0.9953 - val_loss: 0.0169 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01720 to 0.01686, saving model to Result/4096/0406_1603_4096/k_flod/6_0406_1603_weights.best.hdf5\n",
      "Epoch 37/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0102 - acc: 0.9961 - val_loss: 0.0173 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01686\n",
      "Epoch 38/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0104 - acc: 0.9959 - val_loss: 0.0297 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01686\n",
      "Epoch 39/45\n",
      "139320/139320 [==============================] - 617s 4ms/step - loss: 0.0111 - acc: 0.9956 - val_loss: 0.0189 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01686\n",
      "Epoch 40/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0097 - acc: 0.9961 - val_loss: 0.0196 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01686\n",
      "Epoch 41/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0106 - acc: 0.9959 - val_loss: 0.0211 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01686\n",
      "Epoch 42/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0117 - acc: 0.9949 - val_loss: 0.0535 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01686\n",
      "Epoch 43/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0117 - acc: 0.9940 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01686\n",
      "Epoch 44/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0103 - acc: 0.9954 - val_loss: 0.0237 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01686\n",
      "Epoch 45/45\n",
      "139320/139320 [==============================] - 617s 4ms/step - loss: 0.0101 - acc: 0.9957 - val_loss: 0.0360 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01686\n",
      "50400/50400 [==============================] - 72s 1ms/step\n",
      "7 Running...\n",
      "Train on 139320 samples, validate on 15480 samples\n",
      "Epoch 1/45\n",
      "139320/139320 [==============================] - 634s 5ms/step - loss: 0.3578 - acc: 0.8193 - val_loss: 0.1849 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18492, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 2/45\n",
      "139320/139320 [==============================] - 625s 4ms/step - loss: 0.0969 - acc: 0.9607 - val_loss: 0.0879 - val_acc: 0.9652\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18492 to 0.08791, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 3/45\n",
      "139320/139320 [==============================] - 625s 4ms/step - loss: 0.0601 - acc: 0.9756 - val_loss: 0.0484 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08791 to 0.04837, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 4/45\n",
      "139320/139320 [==============================] - 623s 4ms/step - loss: 0.0474 - acc: 0.9806 - val_loss: 0.0483 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04837 to 0.04830, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 5/45\n",
      "139320/139320 [==============================] - 622s 4ms/step - loss: 0.0410 - acc: 0.9839 - val_loss: 0.0345 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04830 to 0.03450, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 6/45\n",
      "139320/139320 [==============================] - 621s 4ms/step - loss: 0.0347 - acc: 0.9860 - val_loss: 0.0506 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03450\n",
      "Epoch 7/45\n",
      "139320/139320 [==============================] - 621s 4ms/step - loss: 0.0325 - acc: 0.9871 - val_loss: 0.0565 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03450\n",
      "Epoch 8/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0296 - acc: 0.9885 - val_loss: 0.0390 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03450\n",
      "Epoch 9/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0273 - acc: 0.9894 - val_loss: 0.0271 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03450 to 0.02708, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 10/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0243 - acc: 0.9904 - val_loss: 0.0465 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02708\n",
      "Epoch 11/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0231 - acc: 0.9908 - val_loss: 0.0303 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02708\n",
      "Epoch 12/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0220 - acc: 0.9912 - val_loss: 0.0253 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02708 to 0.02533, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 13/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0210 - acc: 0.9919 - val_loss: 0.0351 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02533\n",
      "Epoch 14/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0209 - acc: 0.9922 - val_loss: 0.0276 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02533\n",
      "Epoch 15/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0191 - acc: 0.9926 - val_loss: 0.0324 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02533\n",
      "Epoch 16/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0182 - acc: 0.9929 - val_loss: 0.0223 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02533 to 0.02235, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 17/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0170 - acc: 0.9933 - val_loss: 0.0267 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02235\n",
      "Epoch 18/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0174 - acc: 0.9929 - val_loss: 0.0224 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02235\n",
      "Epoch 19/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0163 - acc: 0.9932 - val_loss: 0.0239 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02235\n",
      "Epoch 20/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0160 - acc: 0.9936 - val_loss: 0.0224 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02235\n",
      "Epoch 21/45\n",
      "139320/139320 [==============================] - 620s 4ms/step - loss: 0.0157 - acc: 0.9941 - val_loss: 0.0175 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02235 to 0.01745, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 22/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0140 - acc: 0.9942 - val_loss: 0.0235 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01745\n",
      "Epoch 23/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0152 - acc: 0.9938 - val_loss: 0.0411 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01745\n",
      "Epoch 24/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0140 - acc: 0.9945 - val_loss: 0.0199 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01745\n",
      "Epoch 25/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0129 - acc: 0.9947 - val_loss: 0.0216 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01745\n",
      "Epoch 26/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0149 - acc: 0.9944 - val_loss: 0.0163 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01745 to 0.01635, saving model to Result/4096/0406_1603_4096/k_flod/7_0406_1603_weights.best.hdf5\n",
      "Epoch 27/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0130 - acc: 0.9950 - val_loss: 0.0652 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01635\n",
      "Epoch 28/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0129 - acc: 0.9952 - val_loss: 0.0194 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01635\n",
      "Epoch 29/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0123 - acc: 0.9953 - val_loss: 0.0171 - val_acc: 0.9941\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01635\n",
      "Epoch 30/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0132 - acc: 0.9950 - val_loss: 0.0231 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01635\n",
      "Epoch 31/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0123 - acc: 0.9949 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01635\n",
      "Epoch 32/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0131 - acc: 0.9952 - val_loss: 0.0175 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01635\n",
      "Epoch 33/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.0445 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01635\n",
      "Epoch 34/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0116 - acc: 0.9953 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01635\n",
      "Epoch 35/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0117 - acc: 0.9956 - val_loss: 0.0253 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01635\n",
      "Epoch 36/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0115 - acc: 0.9956 - val_loss: 0.0240 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01635\n",
      "50400/50400 [==============================] - 71s 1ms/step\n",
      "8 Running...\n",
      "Train on 139320 samples, validate on 15480 samples\n",
      "Epoch 1/45\n",
      "139320/139320 [==============================] - 636s 5ms/step - loss: 0.3231 - acc: 0.8354 - val_loss: 0.2873 - val_acc: 0.8982\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28731, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 2/45\n",
      "139320/139320 [==============================] - 627s 5ms/step - loss: 0.0872 - acc: 0.9645 - val_loss: 0.0991 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28731 to 0.09907, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 3/45\n",
      "139320/139320 [==============================] - 626s 4ms/step - loss: 0.0571 - acc: 0.9768 - val_loss: 0.1036 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09907\n",
      "Epoch 4/45\n",
      "139320/139320 [==============================] - 625s 4ms/step - loss: 0.0444 - acc: 0.9817 - val_loss: 0.1876 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09907\n",
      "Epoch 5/45\n",
      "139320/139320 [==============================] - 625s 4ms/step - loss: 0.0401 - acc: 0.9840 - val_loss: 0.0708 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09907 to 0.07077, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 6/45\n",
      "139320/139320 [==============================] - 639s 5ms/step - loss: 0.0358 - acc: 0.9854 - val_loss: 0.0359 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07077 to 0.03585, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 7/45\n",
      "139320/139320 [==============================] - 644s 5ms/step - loss: 0.0323 - acc: 0.9868 - val_loss: 0.1758 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03585\n",
      "Epoch 8/45\n",
      "139320/139320 [==============================] - 644s 5ms/step - loss: 0.0281 - acc: 0.9883 - val_loss: 0.0591 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03585\n",
      "Epoch 9/45\n",
      "139320/139320 [==============================] - 643s 5ms/step - loss: 0.0276 - acc: 0.9885 - val_loss: 0.0435 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03585\n",
      "Epoch 10/45\n",
      "139320/139320 [==============================] - 643s 5ms/step - loss: 0.0256 - acc: 0.9893 - val_loss: 0.0391 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03585\n",
      "Epoch 11/45\n",
      "139320/139320 [==============================] - 643s 5ms/step - loss: 0.0240 - acc: 0.9900 - val_loss: 0.0317 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03585 to 0.03174, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 12/45\n",
      "139320/139320 [==============================] - 633s 5ms/step - loss: 0.0220 - acc: 0.9907 - val_loss: 0.0849 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03174\n",
      "Epoch 13/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.0219 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03174 to 0.02194, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 14/45\n",
      "139320/139320 [==============================] - 619s 4ms/step - loss: 0.0203 - acc: 0.9921 - val_loss: 0.0427 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02194\n",
      "Epoch 15/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0197 - acc: 0.9915 - val_loss: 0.0388 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02194\n",
      "Epoch 16/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0181 - acc: 0.9926 - val_loss: 0.0218 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02194 to 0.02181, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 17/45\n",
      "139320/139320 [==============================] - 618s 4ms/step - loss: 0.0169 - acc: 0.9930 - val_loss: 0.0179 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02181 to 0.01786, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 18/45\n",
      "139320/139320 [==============================] - 621s 4ms/step - loss: 0.0175 - acc: 0.9926 - val_loss: 0.0421 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01786\n",
      "Epoch 19/45\n",
      "139320/139320 [==============================] - 633s 5ms/step - loss: 0.0160 - acc: 0.9933 - val_loss: 0.0294 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01786\n",
      "Epoch 20/45\n",
      "139320/139320 [==============================] - 634s 5ms/step - loss: 0.0160 - acc: 0.9936 - val_loss: 0.0291 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01786\n",
      "Epoch 21/45\n",
      "139320/139320 [==============================] - 629s 5ms/step - loss: 0.0146 - acc: 0.9940 - val_loss: 0.0198 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01786\n",
      "Epoch 22/45\n",
      "139320/139320 [==============================] - 629s 5ms/step - loss: 0.0152 - acc: 0.9940 - val_loss: 0.0189 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01786\n",
      "Epoch 23/45\n",
      "139320/139320 [==============================] - 634s 5ms/step - loss: 0.0146 - acc: 0.9939 - val_loss: 0.0253 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01786\n",
      "Epoch 24/45\n",
      "139320/139320 [==============================] - 635s 5ms/step - loss: 0.0142 - acc: 0.9938 - val_loss: 0.0409 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01786\n",
      "Epoch 25/45\n",
      "139320/139320 [==============================] - 645s 5ms/step - loss: 0.0147 - acc: 0.9944 - val_loss: 0.0230 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01786\n",
      "Epoch 26/45\n",
      "139320/139320 [==============================] - 636s 5ms/step - loss: 0.0123 - acc: 0.9951 - val_loss: 0.0176 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01786 to 0.01762, saving model to Result/4096/0406_1603_4096/k_flod/8_0406_1603_weights.best.hdf5\n",
      "Epoch 27/45\n",
      "124928/139320 [=========================>....] - ETA: 1:03 - loss: 0.0135 - acc: 0.9945"
     ]
    }
   ],
   "source": [
    "ksize = 10\n",
    "pice = int(X_train.shape[0]/ ksize)\n",
    "print('k-fold Floder created') if os.path.isdir(rf_path +'/k_flod') else os.mkdir(rf_path+'/k_flod')\n",
    "for k in range(6,ksize):\n",
    "    fp = open(rf_path+'/Result_'+nowtime+'.txt','a')\n",
    "    trainX = X_train[np.r_[0:k*pice,(k+1)*pice:X_train.shape[0]]]\n",
    "    trainY = Y_train[np.r_[0:k*pice,(k+1)*pice:X_train.shape[0]]]\n",
    "    valX = X_train[np.r_[k*pice:(k+1)*pice]]\n",
    "    valY = Y_train[np.r_[k*pice:(k+1)*pice]]\n",
    "    print(\"\\n\",file=fp)\n",
    "    print(str(k)+\" Running...\")\n",
    "    print(\"\\n\",file=fp)\n",
    "    print(str(k)+\" Running...\",file=fp)\n",
    "    # create model\n",
    "    Kmodel = unet_model.ZF_UNET_224(subseq=subseq, filters=32, INPUT_CHANNELS=N_FEATURES, OUTPUT_MASK_CHANNELS=classes)\n",
    "    # Compile model\n",
    "    optim = Adam(lr=learning_rate)\n",
    "    Kmodel.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "    # checkpoint\n",
    "    lr_reducer = ReduceLROnPlateau(monitor='val_loss',factor=np.sqrt(0.1),cooldown=0,patience=10, min_lr=1e-12)\n",
    "    filepath=rf_path+'/k_flod/'+str(k)+'_'+nowtime+'_'+\"weights.best.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss',mode='min',verbose=1, save_best_only=True)   \n",
    "    early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='auto',baseline=None)\n",
    "    # save best weight model\n",
    "    callbacks = [lr_reducer, early_stopper, checkpoint]\n",
    "    \n",
    "    # Fit the model\n",
    "    khistor =Kmodel.fit(trainX, trainY,validation_data=(valX, valY),batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
    "    '''\n",
    "    #-------------------------------获取模型最后一层的数据--------------------------------\n",
    "    #-------------------------------與PCA,tSNE降维分析-------------------------------------\n",
    "    trucated_model=unet_model.create_truncate_model(Kmodel,subseq=subseq,filters=32,INPUT_CHANNELS=N_FEATURES,OUTPUT_MASK_CHANNELS=classes)\n",
    "    val_hidden_features = trucated_model.predict(valX)\n",
    "    plot_TSNE(val_hidden_features,valY,k,'validation_set',rf_path)\n",
    "    del val_hidden_features\n",
    "    \n",
    "    plot_TSNE(test_hidden_features,Y_test,k,'test_set',rf_path)\n",
    "    test_hidden_features = trucated_model.predict(X_test)\n",
    "    del test_hidden_features\n",
    "    '''\n",
    "    # evaluate the model\n",
    "    valKscores = Kmodel.evaluate(valX, valY, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (Kmodel.metrics_names[1], valKscores[1]*100), file=fp)\n",
    "    print(\"%s: %.2f%%\" % (Kmodel.metrics_names[0], valKscores[0]), file=fp)\n",
    "    valcvscores.append(valKscores)\n",
    "\n",
    "   \n",
    "    testKscores = Kmodel.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "    print(\"test lost:\" + str(testKscores[0]) + \"   test accuracy:\" + str(testKscores[1]) + '\\n',file=fp)\n",
    "    testcvscores.append(testKscores)\n",
    "    \n",
    "    # flod save\n",
    "    file_model = rf_path+'/k_flod/'+str(k)+'_Model_'+nowtime + '_'+ str(subseq) +'_' + str(batch_size) + '_' + optim_type + '.h5py'\n",
    "    Kmodel.save(file_model)\n",
    "    file_weight = rf_path+'/k_flod/'+str(k)+'_Weight_'+nowtime + '_'+ str(subseq) +'_' + str(batch_size) + '_' + optim_type + '.h5py'\n",
    "    Kmodel.save_weights(file_weight)\n",
    "    from openpyxl import load_workbook\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    khist_df = pd.DataFrame(khistor.history) \n",
    "    # save to csv: \n",
    "    if os.path.isfile(rf_path+'/'+nowtime+'_history.xlsx'):\n",
    "        book = load_workbook(rf_path+'/'+nowtime+'_history.xlsx')     \n",
    "        writer = pd.ExcelWriter(rf_path+'/'+nowtime+'_history.xlsx', engine='openpyxl')\n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    else:\n",
    "        writer = pd.ExcelWriter(rf_path+'/'+nowtime+'_history.xlsx')\n",
    "        \n",
    "    khist_df.to_excel(writer,str(k)+'_flod')\n",
    "    writer.save()\n",
    "    fp.close()\n",
    "    \n",
    "    del trainX,trainY, valX, valY, Kmodel,khist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02999345354218263, 0.9887787407769097], [0.07723932808133152, 0.9787333713107639]]\n",
      "[[0.029805682573560626, 0.9890773071289063], [0.07482893347367645, 0.9793318725585938]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(Kmodel.metrics_names)\n",
    "#print(Kscores)\n",
    "#valcvscores1=np.array[valcvscores]\n",
    "print( valcvscores)\n",
    "print( testcvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "nowtime = '0321_0205'\n",
    "from openpyxl import load_workbook\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    #khist_df = pd.DataFrame(khistor.history) \n",
    "    # save to csv: \n",
    "if os.path.isfile(rf_path+'/'+nowtime+'_history.xlsx'):\n",
    "    book = load_workbook(rf_path+'/'+nowtime+'_history.xlsx')     \n",
    "    writer = pd.ExcelWriter(rf_path+'/'+nowtime+'_history.xlsx', engine='openpyxl')\n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    \n",
    "    khist_df.to_excel(writer,str(k)+'_flod')\n",
    "    writer.save()\n",
    "    print('finish')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainX,trainY, valX, valY\n",
    "del Kmodel,optim,lr_reducer,callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model finish\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "fp = open(rf_path+'/Result_'+nowtime+'.txt','a')\n",
    "print(\"\\n\",file=fp)\n",
    "print(\"acc\",file=fp)\n",
    "print(\"mean:\"+str(np.mean(valcvscores[1,:])*100),file=fp)\n",
    "print(\"std:\"+str(np.std(valcvscores[1,:])),file=fp)\n",
    "print(\"loss\",file=fp)\n",
    "print(\"mean:\"+str(np.mean(valcvscores[0,:])),file=fp)\n",
    "print(\"std:\"+str(np.std(valcvscores[0,:])),file=fp)\n",
    "\n",
    "print(\"\\n\",file=fp)\n",
    "print(\"test\",file=fp)\n",
    "print(\"mean:\"+str(np.mean(testcvscores[1,:])*100),file=fp)\n",
    "print(\"std:\"+str(np.std(testcvscores[1,:])),file=fp)\n",
    "print(\"loss\",file=fp)\n",
    "print(\"mean:\"+str(np.mean(testcvscores[0,:])),file=fp)\n",
    "print(\"std:\"+str(np.std(testcvscores[0,:])),file=fp)\n",
    "'''\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "cvsval_df = pd.DataFrame(valcvscores,columns=['loss','acc']) \n",
    "cvstest_df = pd.DataFrame(testcvscores,columns=['loss','acc']) \n",
    "# or save to csv:\n",
    "writercvscore  = pd.ExcelWriter(rf_path+'/'+nowtime+'_cvscore.xlsx')\n",
    "cvsval_df.to_excel(writercvscore,'val')\n",
    "cvstest_df.to_excel(writercvscore,'test')\n",
    "fp.close()\n",
    "writer.close()                              \n",
    "writercvscore.close()\n",
    "print('Train model finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auto split ##\n",
    "epochs = 45 #50\n",
    "batch_size = 64 #64 #128\n",
    "optim_type = 'adam'\n",
    "learning_rate = 0.02 # 0.05 # 0.01 #0.02\n",
    "sum_time = 0\n",
    "net = 'unet'\n",
    "block = '5'\n",
    "\n",
    "if (net == 'unet')and(block == '5'):\n",
    "    model = unet_model.ZF_UNET_224(subseq=subseq, filters=32, INPUT_CHANNELS=N_FEATURES, OUTPUT_MASK_CHANNELS=classes)\n",
    "elif (net == 'unet')and(block == '4'):\n",
    "    model = unet_model.ZF_UNET_224_4(subseq=subseq, filters=32, INPUT_CHANNELS=N_FEATURES, OUTPUT_MASK_CHANNELS=classes)\n",
    "elif (net == 'unet')and(block == '3'):\n",
    "    model = unet_model.ZF_UNET_224_3(subseq=subseq, filters=32, INPUT_CHANNELS=N_FEATURES,\n",
    "                                     OUTPUT_MASK_CHANNELS=classes)\n",
    "elif (net == 'unet')and(block == '2'):\n",
    "    model = unet_model.ZF_UNET_224_2(subseq=subseq, filters=32, INPUT_CHANNELS=N_FEATURES,\n",
    "                                     OUTPUT_MASK_CHANNELS=classes)\n",
    "elif (net == 'segnet')and(block == '5'):\n",
    "    model = segnet.segnet(subseq=subseq, INPUT_CHANNELS=N_FEATURES, filters=64, n_labels=classes, kernel=3,\n",
    "                          pool_size=(1, 2))\n",
    "elif net == 'fcn':\n",
    "    model = unet_model.FCN(inputsize=subseq, deconv_output_size=subseq, INPUT_CHANNELS=N_FEATURES,\n",
    "                           num_classes=classes)\n",
    "elif net == 'maskrcnn':\n",
    "    model = maskrcnn.Mask(subseq=28, INPUT_CHANNELS=N_FEATURES, filters=32, n_labels=classes, kernel=3)\n",
    "\n",
    "# model = segnet.segnet(subseq=subseq, INPUT_CHANNELS=N_FEATURES,filters=64, n_labels = act_classes, kernel=3, pool_size=(1, 2))\n",
    "# model = segnet.segnet4(subseq=subseq, INPUT_CHANNELS=N_FEATURES,filters=64, n_labels = act_classes, kernel=3, pool_size=(1, 2))\n",
    "# model = segnet.segnet3(subseq=subseq, INPUT_CHANNELS=N_FEATURES,filters=64, n_labels = act_classes, kernel=3, pool_size=(1, 2))\n",
    "# model = segnet.segnet2(subseq=subseq, INPUT_CHANNELS=N_FEATURES,filters=64, n_labels = act_classes, kernel=3, pool_size=(1, 2))\n",
    "\n",
    "# model = maskrcnn.Mask(subseq=28, INPUT_CHANNELS=N_FEATURES, filters=32, n_labels=act_classes,kernel=3)\n",
    "\n",
    "# model = unet_model.FCN(inputsize=subseq,deconv_output_size=subseq,INPUT_CHANNELS=N_FEATURES,num_classes=act_classes)\n",
    "# model = unet_model.ZF_UNET_224_3(subseq=subseq,filters=32, INPUT_CHANNELS=N_FEATURES, OUTPUT_MASK_CHANNELS=act_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optim_type == 'SGD':\n",
    "    optim = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    optim = Adam(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                            factor=np.sqrt(0.1),\n",
    "                            cooldown=0,\n",
    "                            patience=10, min_lr=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=rf_path+'/'+nowtime+'_'+\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss',mode='min',verbose=1, save_best_only=True)   # save best model\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]  \n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, mode='auto',baseline=None)\n",
    "callbacks = [lr_reducer, early_stopper, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Model fitting\")\n",
    "history=model.fit(X_train,  Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks)\n",
    "print(\"Model fitting is finished\")\n",
    "acc=np.array(history.history['acc'])\n",
    "loss=np.array(history.history['loss'])\n",
    "val_acc = np.array(history.history['val_acc'])\n",
    "val_loss = np.array(history.history['val_loss'])\n",
    "for i in range(acc.shape[0]):\n",
    "    logging.info('Epoch: {} loss: {:.4f} accuracy{:.4f} val_loss: {:.4f} val_accuracy{:.4f}%\\n'.format(i+1, loss[i], acc[i],val_loss[i],val_acc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc_train', 'acc_val'], loc='upper left')\n",
    "plt.savefig(rf_path+'/'+nowtime+'_'+str(subseq)+'_'+dbName+'_U Net_model_acc_'+ str(batch_size)+'.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(30)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('U net Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss_train','loss_val'], loc='upper left')\n",
    "plt.savefig(rf_path+'/'+nowtime+'_'+str(subseq)+'_'+dbName+'_U Net_model_loss_'+ str(batch_size)+'.png')\n",
    "plt.show()\n",
    "\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.clock()\n",
    "testloss, testaccuracy = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "end = time.clock()\n",
    "sum_time += (end - start)\n",
    "print(str(end - start))\n",
    "print(\"test lost:\" + str(testloss) + \"   test accuracy:\" + str(testaccuracy),file=fp)\n",
    "logging.info('mean_time={}'.format(str(end - start)))\n",
    "\n",
    "\n",
    "y_test_resh = Y_test.reshape(Y_test.shape[0], Y_test.shape[2], -1)\n",
    "y_test_resh_argmax = np.argmax(y_test_resh, axis=2)\n",
    "labels_test_unary = y_test_resh_argmax.reshape(y_test_resh_argmax.size)\n",
    "file_labels_test_unary = rf_path+'/'+nowtime +'_labels_gd_'+dbName+'_'+str(subseq)+'_'+ net+ str(block)+'.npy'\n",
    "np.save(file_labels_test_unary,labels_test_unary)\n",
    "\n",
    "y_pred_raw = model.predict(X_test, batch_size=batch_size)\n",
    "y_pred_resh = y_pred_raw.reshape(y_pred_raw.shape[0], y_pred_raw.shape[2], -1)\n",
    "y_pred_resh_argmax = np.argmax(y_pred_resh, axis=2)\n",
    "y_pred = y_pred_resh_argmax.reshape(y_pred_resh_argmax.size)\n",
    "y_pred_prob = y_pred_resh.reshape(y_pred_resh_argmax.size,y_pred_resh.shape[2])\n",
    "print(\"---------------------------\",file=fp)\n",
    "print(y_pred_prob.shape,file=fp)\n",
    "file_y_pred =rf_path+'/'+nowtime+ '_y_pred_'+dbName+'_'+str(subseq)+'_'+net+'_'+block+'_'+optim_type+'.npy'\n",
    "np.save(file_y_pred,y_pred)\n",
    "file_y_pred_prob = rf_path+'/'+nowtime+'_y_pred_prob_'+dbName+'_'+str(subseq)+'_'+net+'_'+block+'_'+optim_type+'.npy'\n",
    "np.save(file_y_pred_prob,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean absolute error (MAE):      %f\" % sklearn.metrics.mean_absolute_error(labels_test_unary,y_pred),file=fp)\n",
    "print(\"Mean squared error (MSE):       %f\" % sklearn.metrics.mean_squared_error(labels_test_unary,y_pred),file=fp)\n",
    "print(\"Root mean squared error (RMSE): %f\" % math.sqrt(sklearn.metrics.mean_squared_error(labels_test_unary,y_pred)),file=fp)\n",
    "print(\"R square (R^2):                 %f\" % sklearn.metrics.r2_score(labels_test_unary,y_pred),file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nowtime,file=fp)\n",
    "print('Test before saves:', model.predict(X_test[0:2]),file=fp)\n",
    "file_model = rf_path+'/Model_'+nowtime + '_'+ str(subseq) +'_' + str(batch_size) + '_' + optim_type + '.h5py'\n",
    "model.save(file_model)\n",
    "file_weight = rf_path+'/Weight_'+nowtime + '_'+ str(subseq) +'_' + str(batch_size) + '_' + optim_type + '.h5py'\n",
    "model.save_weights(file_weight)\n",
    "fp.close()\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = rf_path+'/'+nowtime+'_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
